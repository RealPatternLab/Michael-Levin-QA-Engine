# levin-qa-engine

This project builds a Retrieval-Augmented Generation (RAG) system to simulate interacting with the ideas of researcher **Michael Levin**. Using a small set of manually collected research papers, we construct a local pipeline that can answer questions grounded in Levin's published work.

## ğŸ¯ Goals

- Understand Michael Levin's core ideas through direct interaction
- Deepen ML engineering skills in:
  - RAG pipelines
  - Embeddings & vector databases
  - LangChain or LlamaIndex
  - Modular ML pipelines
- Build a foundation for later automation via agentic systems

## ğŸ—ï¸ **Architectural Principles** â­ **CRITICAL**

### **Interface-First Design**
This project follows an **interface-first design philosophy** for all external integrations:

- **Abstract Interfaces**: Define clear contracts for each external service
- **Multiple Implementations**: Support multiple providers for each service
- **Dependency Injection**: Use factory patterns to swap implementations
- **Centralized Configuration**: All settings in one place
- **Capability Documentation**: Clear metadata about provider capabilities

### **Code Organization & Simplicity** â­ **CRITICAL**
This project emphasizes **organized and simple code**:

- **Keep Related Classes Together**: Classes of the same nature should be in the same file
- **Minimize File Count**: Don't create separate files for every class unless there's a clear benefit
- **Logical Grouping**: Group related functionality in the same module
- **Avoid Over-Engineering**: Don't create abstractions unless they solve a real problem
- **Clear File Names**: Use descriptive names that indicate the file's purpose

#### **When to Put Classes in the Same File:**
- âœ… **Same Interface**: All implementations of the same interface (e.g., `OpenAITextExtractor` and `ClaudeTextExtractor`)
- âœ… **Related Functionality**: Classes that work together or are part of the same feature
- âœ… **Small Classes**: Helper classes, data classes, or utility classes
- âœ… **Same Domain**: Classes that handle the same type of data or operations

#### **When to Separate Classes:**
- âŒ **Different Interfaces**: Classes implementing different interfaces
- âŒ **Large Classes**: When a file becomes too large (>500 lines) or complex
- âŒ **Different Domains**: Classes that handle completely different concerns
- âŒ **Optional Dependencies**: Classes that require different dependencies

#### **Example Organization:**
```python
# âœ… GOOD: Related classes in same file
# modules/text_extraction/openai.py
class OpenAITextExtractor(BaseTextExtractor):
    """OpenAI implementation for text extraction."""
    pass

class OpenAIBatchProcessor:
    """Helper class for OpenAI batch processing."""
    pass

# âœ… GOOD: Interface and implementations together
# modules/text_extraction/base.py
class TextExtractionInterface(ABC):
    """Abstract interface for text extraction."""
    pass

class BaseTextExtractor(TextExtractionInterface):
    """Base implementation with common functionality."""
    pass

# âŒ BAD: Unnecessary file separation
# modules/text_extraction/openai_extractor.py  # Just one class
# modules/text_extraction/openai_batch_processor.py  # Just one class
```

### **Why This Matters**
- **Technology Evolution**: APIs change, new providers emerge
- **Cost Optimization**: Different providers have different pricing
- **Performance Flexibility**: Some tasks need speed, others need quality
- **Reliability**: Redundancy and fallback options
- **Testing**: Easy to mock and test different scenarios
- **Maintainability**: Simple, organized code is easier to understand and modify
- **Onboarding**: New developers can quickly understand the codebase structure

### **Current Implementations**
- âœ… **AI Models**: `ai_models/` - OpenAI, Claude, Gemini, Local
- âœ… **PDF Processing**: `modules/pdf_processing/` - Image rendering for multimodal analysis
- âœ… **Text Extraction**: `modules/text_extraction/` - Multimodal text extraction from PDF images
- âœ… **Storage**: `modules/storage/` - JSON-based job tracking and results persistence
- ğŸ”„ **Vector Databases**: Future - FAISS, ChromaDB, Pinecone
- ğŸ”„ **Embedding Models**: Future - OpenAI, SentenceTransformers, Local

### **Example Pattern**
```python
# âœ… GOOD: Interface-based approach
from ai_models import get_model
model = get_model("openai")  # Easy to swap to "claude" or "local"

# âŒ BAD: Direct API calls scattered throughout code
from openai import OpenAI
client = OpenAI(api_key=key)  # Hard to swap, test, or mock
```

**See `.cursor/docs/interface_guidelines.md` for detailed implementation guidelines.**
**See `.cursor/rules/code-organization.md` for detailed code organization guidelines.**

## âœ… Phase 1 Scope

- Manually download 3â€“5 PDFs
- **Render PDF pages to images for multimodal analysis**
- **Extract text using multimodal LLMs (GPT-4o, Claude)**
- Chunk text into semantic blocks
- Generate vector embeddings
- Store in FAISS or ChromaDB
- Query with LangChain RAG pipeline
- Deliver answers via CLI or Streamlit app

## ğŸ§± Stack

- Python 3.11+
- **UV** for package management
- **Ruff** for code quality and formatting
- **PyMuPDF** for PDF image rendering
- **OpenAI GPT-4o** for multimodal text extraction
- FAISS or ChromaDB
- LangChain or LlamaIndex
- OpenAI or SentenceTransformers
- Streamlit (optional)
- GCP (planned in later phase)

## ğŸ“ Project Structure

```
levin-qa-engine/
â”œâ”€â”€ ai_models/              # Centralized AI model interface
â”‚   â”œâ”€â”€ __init__.py         # Factory functions and registry
â”‚   â”œâ”€â”€ base.py             # BaseModelInterface abstract class
â”‚   â””â”€â”€ openai_model.py     # OpenAI implementation
â”œâ”€â”€ modules/                 # Core processing modules
â”‚   â”œâ”€â”€ pdf_processing/      # PDF image rendering for multimodal analysis
â”‚   â”‚   â”œâ”€â”€ __init__.py     # Factory functions and registry
â”‚   â”‚   â”œâ”€â”€ base.py         # PDFProcessorInterface abstract class
â”‚   â”‚   â”œâ”€â”€ pdfplumber_processor.py
â”‚   â”‚   â””â”€â”€ pymupdf_processor.py
â”‚   â”œâ”€â”€ text_extraction/    # Multimodal LLM text extraction
â”‚   â”‚   â”œâ”€â”€ __init__.py     # Factory functions and registry
â”‚   â”‚   â”œâ”€â”€ base.py         # TextExtractionInterface abstract class
â”‚   â”‚   â”œâ”€â”€ base_extractor.py
â”‚   â”‚   â””â”€â”€ openai.py
â”‚   â””â”€â”€ storage/            # Results persistence and job management
â”‚       â”œâ”€â”€ __init__.py     # Factory functions and registry
â”‚       â”œâ”€â”€ base.py         # StorageInterface abstract class
â”‚       â””â”€â”€ json_storage.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_papers/         # Store PDF files
â”‚   â”œâ”€â”€ extracted/          # Output from multimodal text extraction pipeline
â”‚   â”‚   â”œâ”€â”€ page_images/    # Rendered PDF page images
â”‚   â”‚   â”œâ”€â”€ extracted_texts/ # Extracted text files
â”‚   â”‚   â””â”€â”€ results/        # Extraction results and metadata
â”‚   â””â”€â”€ jobs_metadata/      # Job tracking and metadata
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_cleaning_pipeline.py  # Main multimodal text extraction pipeline
â”‚   â””â”€â”€ test/               # Test scripts for components
â”œâ”€â”€ .cursor/                # Documentation and development rules
â”‚   â”œâ”€â”€ docs/               # Project documentation
â”‚   â””â”€â”€ rules/              # Development rules for AI assistance
â””â”€â”€ config.py               # Centralized configuration
```

## ğŸš€ **Multimodal Text Extraction Pipeline**

This project uses a **multimodal approach** for PDF text extraction:

1. **PDF Image Rendering**: Render PDF pages to high-quality images
2. **Multimodal LLM Analysis**: Use GPT-4o or Claude to extract text from images
3. **Quality Assessment**: Evaluate extraction quality and generate warnings
4. **Structured Output**: Save extracted text with metadata and results

### **Key Benefits**
- âœ… **No PDF parsing issues** - let the LLM handle complex layouts
- âœ… **Better accuracy** - multimodal models understand visual structure
- âœ… **Simpler architecture** - fewer moving parts and dependencies
- âœ… **More reliable** - works with any PDF format or layout

### **Usage**
```bash
# Extract text from a PDF using multimodal LLM
PYTHONPATH=. uv run python scripts/run_cleaning_pipeline.py \
  --pdf data/raw_papers/paper.pdf \
  --output data/extracted \
  --verbose
```

## ğŸš€ Development Setup

### Prerequisites
- Python 3.11+
- UV package manager
- Git

### Quick Start
```bash
# Clone the repository
git clone <repository-url>
cd levin-qa-engine

# Switch to dev branch
git checkout dev

# Install dependencies (as needed)
uv add <package-name>

# Run scripts
uv run python scripts/script.py

# Lint and format code
uv run ruff check
uv run ruff format
```

## ğŸ¯ Learning & Scaling Strategy

### Phase 1: Local Learning (Current Focus)
- **Goal**: Master RAG fundamentals hands-on
- **Environment**: Local development with UV
- **Tools**: FAISS/ChromaDB, LangChain, local embeddings
- **Outcome**: Working prototype with deep understanding

### Phase 2: GCP Cloud Migration (Future)
- **Goal**: Scale for production and advanced features
- **Environment**: Google Cloud Platform
- **Services**: Cloud Run, Cloud Storage, Vertex AI
- **Benefits**: Auto-scaling, managed services, cost optimization

## ğŸ“ Development Rules

- **MUST use UV** for all Python package management
- **MUST use Ruff** for all linting and formatting
- **MUST follow interface-first design** for all external integrations
- **MUST organize scripts in `scripts/`** directory
- **MUST organize modules in `modules/`** directory
- **MUST store data in `data/`** directory
- Add dependencies incrementally as needed
- Follow PEP 8 standards (enforced by Ruff)
- Use type hints where appropriate
- Write docstrings for all functions and classes

## âœ… **Codebase Cleanup Complete!**

### **âœ… What We Removed**

**Old Test Files:**
- `scripts/test_multimodal_extraction.py` - Old multimodal extraction test
- `scripts/test/test_llm_extraction.py` - Traditional text extraction test
- `scripts/test/test_api_key.py` - API key test
- `scripts/test/test_model_swapping.py` - Model swapping test
- `scripts/test/run_tests.py` - Old test runner

**Old Data Directories:**
- `data/test_images/` - Test image files
- `data/cleaned/` - Old cleaning results
- `data/cleaned_pymupdf/` - Old PyMuPDF cleaning results
- `data/test_cleaned/` - Test cleaning results

**Old Data Files:**
- `data/multimodal_extracted_text.txt` - Old test output
- `data/cleaning_jobs.json` â†’ `data/extraction_jobs.json` (renamed)

### **âœ… What We Updated**

**Storage Interface:**
- Updated `modules/storage/base.py` to use extraction terminology
- Updated `modules/storage/json_storage.py` to use simplified job structure
- Renamed methods: `save_cleaning_job` â†’ `save_job`, etc.

**LLM Cleaning Module:**
- Updated `modules/llm_cleaning/__init__.py` to reflect text extraction focus
- Updated registry name: `CLEANING_PROCESSOR_REGISTRY` â†’ `EXTRACTION_PROCESSOR_REGISTRY`

**Documentation:**
- Updated `readme.md` to reflect multimodal text extraction approach
- Added new section explaining the multimodal pipeline benefits

### **âœ… Current Clean Architecture**

```
PDF â†’ Image Rendering â†’ Multimodal LLM â†’ Extracted Text
```

**Key Benefits:**
- âœ… **No traditional PDF text extraction** - eliminated all parsing issues
- âœ… **Simplified codebase** - fewer moving parts and dependencies
- âœ… **Better accuracy** - multimodal models handle complex layouts
- âœ… **Consistent terminology** - all references now use "extraction" instead of "cleaning"
- âœ… **Clean interfaces** - updated all base classes and factory functions

### **ğŸš€ Ready for Production**

The codebase is now clean and focused entirely on the multimodal approach:

```bash
# Extract text from any PDF using multimodal LLM
PYTHONPATH=. uv run python scripts/run_cleaning_pipeline.py \
  --pdf data/raw_papers/paper.pdf \
  --output data/extracted \
  --verbose
```

The refactoring was a great success - we've eliminated the complexity of traditional PDF text extraction and created a much more reliable and accurate system! ğŸ¯

