Machine learning for hypothesis generation in biology and medicine: exploring the latent space of neuroscience and developmental bioelectricity
Thomas O'Brien,ª Joel Stremmel, Da Léo Pio-Lopez,♭ Patrick McMillen,b Cody Rasmussen-Ivey♭ and Michael Levin D *bc

**Introduction**

The scientific enterprise depends critically not only on the skills needed to definitively test crisp hypotheses,1-7 but also on the much less well-understood step of acquiring insights and fruitful research directions.⁸⁻⁹ Many recent discussions¹⁰,¹¹ have focused on the fact that while modern "big data" methods are generating a deluge of facts and measurements, it is increasingly more important to be “building the edifice of science, in addition to throwing bricks into the yard".¹²  We must develop strategies for deriving novel insights and deep hypotheses that cross traditional (often artificial) disciplinary boundaries.  We must improve, at a pace that keeps up with technological and data science advances, our ability to identify symmetries (invariances) between sets of observations and approaches to unify and simplify where possible by identifying large-scale patterns in research literature, thus motivating and enhancing new research programs (Fig. 1).

Artificial intelligence, specifically machine learning,¹³⁻¹⁵ is poised to help science.¹⁴,¹⁶⁻¹⁹ “Robot scientist" platforms can provide number crunching, automation, and high throughput, and potentially guide research by identifying future experiments.²⁰⁻²² Machine learning tools are essential for progress in the bioinformatics of shape²³⁻²⁶ (moving beyond molecular information to understand organ- and organism-level form and function), and developmental biology.²⁷,²⁸  While emphasis is placed on improving the factuality of AI tools, paralleling strong inference and hypothesis-testing in science, the process of generating interesting hypotheses is less well-understood but equally crucial. Our contribution attempts to bolster this ideation with a new AI-based tool for human scientists that provides input into the canonical scientific method.

Recent work includes the AI-based discovery of testable models of regenerative anatomical regulation,²⁹ which were empirically validated,³⁰ and similar efforts in genomics,²² chemistry³¹,³² and biomaterials.³³  A key gap is the paucity of tools for assisting with the creative aspect of identifying deep commonalities between disparate functional datasets, to enable generalized insight from the growing literature.  Tools are needed that leverage human scientists' meta-hypotheses and mine published studies for information that can transform conceptual hunches into actionable research programs.


One interdisciplinary area where computer-assisted discovery is needed is real-time physiology that controls form and function in vivo.  How large-scale anatomy and behavior arise from molecular processes is a canonical systems biology problem.³⁴  It is currently handled by two distinct fields: neuroscience and developmental biology.  Recent work suggests they may share underlying dynamics.³⁵⁻³⁷ Neuroscience understands that behavior and cognition are driven by physiological information processing by neural networks signaling via electrical events at their membranes.³⁸⁻⁴¹ Similarly, bioelectric signaling is instructive in directing complex developmental and regenerative morphogenesis.⁴²⁻⁴⁴ Recent advances in the molecular understanding of developmental bioelectricity⁴⁵⁻⁴⁷ have begun to blur the boundaries between these disciplines.⁴⁸,⁴⁹ (Fig. 2).

Specifically, brains' functional capabilities may originate in more ancient, slower bioelectric networks operating since the emergence of bacterial biofilms⁵⁰⁻⁵⁴ and exploited by evolution to orchestrate metazoan morphogenesis.⁵⁵,⁵⁶ The idea that the same algorithms scale cellular activity into larger competencies (regulative morphogenesis and intelligent behavior) in the brain and body (Fig. 3) has deep implications for porting methods from neuroscience and behavioral science into biomedicine³⁵,⁵⁷,⁵⁸ to leverage neuroscience's paradigms for managing multi-scale causality and inferring effective interventions.

The proposed symmetry between cellular swarms using collective dynamics to solve problems in anatomical morphospace and in 3D classical behavioral space has been empirically tested³⁴,⁴⁷ and has implications for biomedicine and evolutionary biology.⁵⁹,⁶⁰ However, there has been no way to derive these hypotheses at scale from the literature of neuroscience and developmental biophysics. The deep similarity between the role of bioelectric networks in controlling body shape (cellular collectives' behavior) and cognition (organism-level behavior) suggests one could read neuroscience papers as developmental biology papers, by pivoting problem spaces (from 3D space to anatomical morphospace) and time scales (from milliseconds to minutes).⁴⁹,⁵⁶ However, there has been no efficient way to implement this and explore the latent space of hypothetical papers that could provide candidate hypotheses and research directions.

We present FieldSHIFT, a tool helping scientists explore the mapping between developmental bioelectricity and neuroscience and begin exploring the space of scientific studies beyond what is already written. FieldSHIFT is an in-context learning framework using a large language model to convert neuroscience paper abstracts to developmental biology by replacing specific words and concepts.  This generates insightful results that expand scientific intuition and identify testable hypotheses. We test predictions using bioinformatics, revealing quantitative conservation of genes between developmental morphogenesis and cognitive behavior. This system is a first step towards using AI as an imagination-enhancing research tool, deriving insights from published experiments and letting scientists explore life-as-it-could-be.⁶¹ We tested one prediction, finding significant enrichment in overlap between genes implicated in cognitive processes and morphogenesis. There have been related efforts using generative AI for hypothesis generation and cross-domain knowledge discovery, such as MechGPT,⁶²  and approaches focused on knowledge discovery across scientific domains, such as translating between protein sequences and music⁶³ and identifying new designs via cross-domain patent mining.  Our method focuses on generating scientific hypotheses as abstracts via text translations.


**Methods**

FieldSHIFT is a framework for domain translation with modular components: training data and an AI language model. We constructed a dataset of neuroscience and developmental biology sentences and associated concepts to test FieldSHIFT with two AI language models. Trained biologists built the dataset and evaluated the model translations. While focused on mapping neuroscience to developmental biology text, this approach could be applied to other domains.


**Data**

The Levin Lab has manually translated neuroscience to developmental biology for decades by changing concepts like "brain" to "body", "millisecond" to "minute", and "neuron" to "cell". We collected 70 such translation pairs.  Using these, we constructed translations (sentences to abstract-length paragraphs) by matching neuroscience passages with corresponding developmental biology passages, including facts and recently published abstracts.  We collected 1437 translation samples (average length: 209 characters, standard deviation: 375).  An example:

* **Neuroscience:** “The brain is a complex system of neurons that are interconnected by synapses."
* **Developmental Biology:** “The body is a complex system of cells that are interconnected by gap junctions."

We also added the same developmental biology abstract as both input and output to teach the model not to change developmental biology text. Six abstracts (papers⁶⁵⁻⁷⁰) were selected from Levin Lab publications. The dataset is published on Hugging Face: https://huggingface.co/datasets/levinlab/neuroscience-to-dev-bio/tree/main.

To train and test models, we randomly split the dataset by neuroscience concepts: 43 training, 6 validation, and 21 test concepts. We then split associated passages: 503 train, 50 validation, and 57 test passages, achieving a roughly 10:1 ratio of train to validation/test samples.



**Domain translation with machine learning**

We tested two domain translation approaches using pretrained language models:

1. **Fine-tuned BART:**⁷¹,¹,⁷²  This approach is inspired by neural machine translation (NMT) and abstractive summarization. The pretrained BART model, designed for summarizing text, was fine-tuned to map neuroscience text to developmental biology text.

2. **GPT-4:**⁷³,⁷⁴ This approach uses in-context learning to prompt the GPT-4 large language model (LLM) to translate neuroscience text into developmental biology text.

Human evaluation by trained biologists assessed the effectiveness of these approaches.  Transformer LMs, and recently, LLMs, which demonstrate emergent capabilities at scale,⁷⁵ are expressive deep neural networks representing text sequences and achieving state-of-the-art performance on various natural language tasks.⁷⁶⁻⁷⁸  LMs are typically pretrained on large, unannotated corpora, then fine-tuned for specific tasks. Both NMT and summarization involve text generation.  We exploit this in our first approach by fine-tuning an encoder-decoder LM⁷² already trained for summarization.

**Model training**

The BART-based domain translator learns a mapping from one text domain to another (Fig. 4). During fine-tuning, we used positive and negative text pairs. For GPT-4, we provided in-context examples and asked the LLM to complete the pattern, without updating its weights.

**Model validation**

For each test concept, we searched Google Scholar for the first abstract including the term, using the query structure: "(research domain)" "(specific topic)".  Two professional cell/developmental biologists graded the translations.


**Bioinformatics**

We extracted unique genes related to gene ontologies 'Developmental process' (GO:0032502) and 'Behavior' (GO:0007610) in humans, *Drosophila*, zebrafish (*Danio rerio*), and mice (*Mus musculus*) using the Ensembl database and computed the percentage of 'Behavior' genes included in the 'Developmental process' set.


**Results: Comparing domain translators**

Human annotation suggests the effectiveness of ML-based domain translation. The GPT-4-based domain translator with self-critique generated good translations for over half of the neuroscience abstracts. GPT-4 performed significantly better than BART (P = 0.017). Both annotators graded more real abstracts as good than ML-generated abstracts, significant only for one annotator (Tables 1 and 2).


**Hypothesis testing: molecular conservation between cognition and morphogenesis**

One hypothesis generated by FieldSHIFT is that molecular mechanisms behind developmental bioelectricity and cognitive/behavioral phenomena should be conserved, i.e., the same genes implicated in both roles. This is novel because only the idea of "morphogenesis as behavior in anatomical space"³⁷,⁵⁶ predicts any association between genes across these distinct fields.


**Discussion**

**Machine learning for domain translation**

FieldSHIFT is a framework for domain translation.  We built a domain translation dataset and compared two ML approaches. Expert evaluation found the GPT-4-based approach produced good translations, leading to useful hypotheses in about 20 out of 33 tries.


**Bioelectricity: conserved mechanisms and algorithms between control of body and behavior**

It has been hypothesized that algorithms of behavior (active inference, perceptual control, collective decision-making, memory, learning, navigation of problem spaces, preferences, pursuit of goal states, etc.) are used to direct morphogenesis and may even derive from it evolutionarily.⁵⁵,⁵⁶,⁹⁹ Here, we provide a tool to explore the symmetries and commonalities between these fields, and potentially any other two fields.


**Latent space of scientific papers**

This work is the beginning of AI-guided exploration of the latent space around scientific papers, in the sense of the "adjacent possible”.¹⁰⁰,¹⁰¹ Each scientific paper provides access to possible papers where aspects are changed – exploring symmetries of concepts in specific problem spaces.



**Limitations of the study and next steps**

One limitation is the number of manually curated papers; machine learning will improve with more data.



**Conclusion**

The observed overlap between genes implicated in morphogenesis and behavior has implications for experimental work on the evolution and biomedical targeting of these genes.