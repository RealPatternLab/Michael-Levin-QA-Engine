WHAT DOES IT FEEL LIKE TO BE A PANCREAS?

The collective intelligence of evolution and
development

Richard Watson
Electronics and Computer Science/Institute for Life Sciences, University of Southampton, Southampton, UK

Michael Levin
Allen Discovery Center at Tufts University, Medford, MA, USA
Wyss Institute for Biologically Inspired Engineering at Harvard University, Cambridge, MA, USA

Abstract

Collective intelligence and individual intelligence are usually considered to be fundamentally different. Individual intelligence is uncontroversial. It occurs in organisms with special neural machinery, evolved by natural selection to enable cognitive and learning functions that serve the fitness benefit of the organism, and then trained through lifetime experience to maximise individual rewards. Whilst the mechanisms of individual intelligence are not fully understood, good models exist for many aspects of individual cognition and learning. Collective intelligence, in contrast, is a much more ambiguous idea. What exactly constitutes collective intelligence is often vague, and the mechanisms that might enable it are frequently domain-specific. These cannot be mechanisms selected specifically for the purpose of collective intelligence because collectives are not (except in special circumstances) evolutionary units, and it is not clear that collectives can learn the way individual intelligences do since they are not a singular locus of rewards and benefits. Here, we use examples from evolution and developmental morphogenesis to argue that these apparent distinctions are not as categorical as they appear. Breaking down such distinctions enables us to borrow from and expand existing models of individual cognition and learning as a framework for collective intelligence, in particular connectionist models familiar in the context of neural networks. We discuss how specific features of these models inform the necessary and sufficient conditions for collective intelligence, and identify current knowledge gaps as opportunities for future research.

Keywords

Evolution, machine learning, networks, individuality, neural networks

Introduction

The identification of a suitable theoretical framework and appropriate engineering principles for collective intelligence are open problems. In this paper, we begin to address these gaps by developing a synthesis of perspectives usually considered to be quite distinct. To do this, we first dissolve a number of limiting misconceptions that cause collective intelligence and individual intelligence to be treated as separate topics; second, we introduce a speculative conceptual framework to unify them.

For an intelligence to belong properly to a collective, it must arise not from the cleverness of its members but from having the right kind of functional relationships between them. What kinds of functional relationships, and in what specific organisation, are required to turn a collective that is not intelligent into a collective that is? We use a specific understanding of cognition and learning that is already well-developed for individual intelligence to synthesise collective intelligence with aspects of development and evolution.

In particular, we explore how connectionist models of cognition and learning, familiar in neural network models of individual intelligence, can address this question, and how they signpost directions for future research in collective intelligence. We especially emphasise the known emergent properties of cellular collectives as instructive examples of collective intelligence at a sub-organismal scale.

Individual and collective intelligence are distinct phenomena. Or are they?

At first glance, it might seem that models of individual intelligence are not relevant to collective intelligence. Individuals have brains that can cognise and learn, and although colonies and swarms might be composed of individuals with brains, the collective as a whole is not a brain and cannot cognise or learn. Moreover, it is easy to understand why the component parts of an individual work together so well because adaptive processes at the organismic level, such as evolution by natural selection and reward-based reinforcement, select or reward them for doing so. In contrast, collectives are composed of multiple evolutionary units or distributed multi-agent systems and thus present unique credit-assignment problems that complicate reinforcement of such adaptive processes. Such distinctions seem to justify the consideration of collective and organismic intelligences as different topics. We argue that these are false distinctions and there is a bigger, and much more interesting, picture. The basic tenets of this unified view are the following:

All individuals are collectives. All individuals are collectives, made of parts that used to be individuals themselves. This is true not only for multicellular organisms derived from unicellular ancestors but also for eukaryotic cells with multiple organelles arising from bacterial ancestors, and for simpler cells that contain the first chromosomes arising from the union of previously free-living self-replicating molecules. Moreover, the proper functioning of organisms – their robustness, adaptability and evolvability – depends on the continued autonomy of their component parts. Multicellular organisms exhibit multi-scale autonomy, a dynamic interplay of competition and cooperation, and coordinated collective action inherent to their development, function and behaviour, while being a society of cells. Thus, individuals like you and I, and collectives like swarms and colonies, are not as categorically different as they first appear.

All intelligences are collectives. Individual intelligence, in the familiar guise of a central nervous system or a brain, arises from the interaction of many unintelligent components (neurons) arranged in the right organisation with the right connections. This is the foundation of connectionism; that intelligence resides not in the individual parts but in the arrangement of the connections between them. The individual neuron is not where all the interesting cognition and learning occur. It is the distributed collective activity in the network that constitutes cognition and changes to the organisation of network connections that constitute learning. So brains are collectives, thus collectives of the right kind do cognise and learn. In fact, brains provide the archetypal example of an intelligent collective.

Cognition and learning are substrate-independent. The principles of distributed cognition familiar in artificial neural networks can be implemented by any network of signals and non-linear responses to suitably weighted inputs. Gene-regulation networks, ecological networks and social networks can all compute in the same sense as neural networks if the connections are suitably arranged. In development and organismic biology, many different levels of adaptive networks exist aside from neural networks, including gene-regulation networks, protein networks, metabolic networks, morphogen diffusion networks and endocrine systems. In addition, it is clear that morphogenesis, physiological function and the adaptive processes of robustness and repair all require information integration and collective action that constitute cognition – in many cases without neurons. Each of these phenomena exhibits the same learning behaviours, including the storage and retrieval of multiple associative memories, effecting classification and recognition with generalisation capabilities, and learning to solve combinatorial optimisation problems better with experience.

The credit assignment problems inherent in collective intelligence are fundamental in all cognition and learning, and in all biological individuality. It is true that collective intelligence is fundamentally about collectives - meaning that we cannot presuppose the system as a whole to be a single selective or utility-maximising unit. However, when we take a larger perspective – for example, one concerned with their emergence over developmental or evolutionary timescales – neither can we presuppose that apparently unambiguous individuals have always been (single) selective or utility-maximising units. Thus, the credit assignment issues of collective intelligence are not categorically distinct from related core issues in individual adaptation, evolution and intelligence.


Towards a unified theory of intelligence and cognition

In collectives, each component selects behaviours based on the rewards they receive for their own actions. In intelligent systems, the reward feedback is effectively operating at a higher level – and the system as a whole selects behaviours based on the rewards received by the system as a whole. Accordingly, it makes sense that the system selects behaviours that facilitate long-term collective reward. But operationally, each component within the intelligent system is still autonomous, selecting individual actions based on individual rewards given the relational context they find themselves in. The question is, what kinds of interaction structures cause collectives to behave like intelligent agents, exhibiting information integration and coordinated action that effect reward feedback at the system level? Here, we propose a formalism for thinking about these issues as a set of hypotheses to drive future research.


Establishing these commonalities has significant consequences for understanding: since some of these questions have well-developed answers in the context of individual intelligences, those answers can be transferred to provide a framework for approaching collective intelligences. While connectionist models of cognition and learning do not have all the answers, they do identify the kind of relationships that turn a collection of unintelligent components into a collective intelligence, with cognitive and learning abilities that belong to the whole and not the parts. Additionally, connectionist models identify conditions where collective intelligence can arise bottom-up, using only distributed learning mechanisms without system-level or global feedback.

We do not attempt a comprehensive review of the many related topics involved. Rather, we have selected foundational points to clarify a vision of distributed cognition, bottom-up adaptation and, more generally, the ‘more than the sum of the parts' conceptual territory.


A framework for interrogating collective intelligence

Our thinking builds on a core conjecture that the kind of relationships necessary to produce evolutionary individuality – the generation and heritability of fitness differences at the collective level – are the same as those required to produce organismic individuality – the information integration and collective action characteristic of a self. More specifically, we propose that these relationships are cognitive architectures regardless of the substrate in which they are implemented. That is, the causal structures necessary to create fitness that properly belongs to the whole rather than its parts are the same as those required to carry out the integration of information and coordination of action characteristic of a 'self”. We propose that such functionality constitutes cognition in a formal sense, whether the causal structures are implemented by chemical, gene-regulatory, bioelectrical, neural, ecological or social interactions, consistent with the emerging field of unconventional and basal cognition.


Understanding the parallels between individual and collective intelligence via a connectionist framework

The curious thing about collective intelligence is that the more intelligent something is, the less it looks like a collective. When component members act in an efficiently coordinated manner, with behaviours that can be diverted from their short-term self-interest to serve long-term collective interest, a collective looks more like an individual at a higher level of organisation. Recognising this, biology is full of collective intelligence – not just in the weak sense of swarms and colonies with emergent behaviours but because any organism is actually an intelligent collective. Here we look at (1) collective behaviours and functions within organisms, especially development and the idea of 'basal cognition'; (2) the complex relationship between organismal identity and evolutionary units, and how this has changed over evolutionary time; (3) the substrate-independence of intelligence and how cognition and learning can occur in various kinds of biological networks; and briefly, (4) how the problem of credit assignment arises as a core theme in these issues.


Organisms as collective intelligences: Development and basal cognition

All organisms are collectives at multiple levels: from collections of active molecules in a cell, to collections of cells in a multicellular organism or a tissue, to collections of tissues in an individual organism. What makes collectives individuals (as opposed to merely populations in containers) is their intelligence – their degree of competency in solving novel problems. The processes of development are the substrate of this intelligence – the ‘glue’ that makes the whole more than the sum of the parts. A large body of work indicates that development is not well-characterised as the execution of a pre-programmed genetic script but rather as an active, dynamic and adaptive process. Although all cells in most multicellular organisms share the same genome, the remarkable protein machinery that genome encodes, along with the cytoskeletal and lipid structures each cell inherits from its ancestors, enables a collective of embryonic cells to develop differentiated roles and self-organise into a large-scale, functional machine. Development thus involves a multi-scale hierarchy of cooperating and competing subunits, each with local computational and goal-directed capacity, that enables the whole to function as a singular subject of memories and preferences – a unified locus of learning and homeostatic loops that harness its subunits towards goal states.


Morphogenesis as an instantiation of collective intelligence. Anatomical homeostasis – the ability to adjust anatomy despite injury or drastic rearrangement – requires the collective to have a degree of autonomous problem-solving activity in morphospace, defined as the space of possible anatomical configurations. For example, eyes developed ectopically in the tails of frog embryos still allow the animals to see because the eye primordia cells succeed not only in forming an eye and optic nerve in an abnormal environment but also in connecting the optic nerve to the nervous system (in this case, via synapse onto the spinal cord, rather than the brain). Another example is the development of the newt kidney tubule: normally cell-cell communication among ~8 cells produces the correct tubule diameter, but if the cells are made very large, they still produce the same diameter tubule by using fewer cells. Even when cell size gets very large, a single cell can achieve the same diameter tubule by bending around itself (this time using cytoskeletal mechanisms). Thus, genetically wild-type cells can harness distinct molecular components, depending on the novel circumstances, to reach the same high-level anatomical goal. This disrupts a straightforward reductionist or bottom-up account of organismal morphology and function. Whilst natural selection provides the genetic hardware, this hardware has a very particular kind of plasticity, which implements robustness to both external and internal novelty. This derives from an architecture of multi-scale competency, where many subsystems are themselves goal-directed and can pursue specific endpoints despite changes in their tissue environment, greatly potentiating evolvability. The idea of organisms as pre-specified machines, assembled by genetic scripts, fails in the context of these and other examples of developmental robustness. We therefore seek to understand these capacities in the context of a different and more flexible conceptual space.

Basal cognition in development: Morphological problem-solving. ‘Basal cognition’ refers to information processing that occurs in an unconventional substrate and/or as a simpler evolutionary precursor to what we conventionally consider cognition. This is not cognition that depends on neurons or necessarily involves second-order self-awareness. It refers to cognition in an algorithmic sense that is substrate-independent and is observable as problem-solving across phylogenetic history. What is important in basal cognition is not the presence of neurons but the presence of functional and informational interactions that facilitate both information integration and the ability to orchestrate cued responses that coordinate action. This can be implemented by suitable interactions of any nature including gene regulatory networks, cell signalling, bio-electric networks and morphogenetic chemical feedbacks.

For example, the process of growing a limb constitutes basal cognition, as it requires both integration of multi-dimensional information (e.g. to ‘decide’ appendage type or handedness, from context) and collective action to put this ‘basal decision’ into action (e.g. to coordinate the timing, abundance and positioning of cellular differentiation and growth). More broadly, regulative development, regeneration and remodelling (such as morphogenesis) require collective decision making and memory at two scales: on the part of cells (collectives of molecular networks) and of tissues (collectives of cells). Limb re-generation, for example, requires a memory of the correct pattern, the ability to compare current state with the target state and the ability to traverse anatomical morphospace in different ways depending on context and perturbations.

William James’ definition of intelligence – the ability to achieve the same goal in multiple ways – provides context for considering the basal intelligence of cell collectives in morphogenesis. It has become clear that the large-scale morphological goals of an organism override and harness the local competencies of individual cells to adaptively navigate morphospace. That navigation capacity is not hardwired but shows considerable problem-solving plasticity. Numerous examples indicate that morphogenesis meets James’s definition of intelligence by achieving normal anatomy despite a wide range of serious perturbations. For example, developing *Xenopus* tadpoles can attain the same anatomical outcome despite starting with their craniofacial organs scrambled or with the wrong number of cells. Even mammalian embryos can overcome drastic perturbations such as amputation; and early embryo splitting in humans results in normal monozygotic twins rather than partial bodies.


The ability of collectives of cells to pursue, with various degrees of competency, target states in anatomical morphospace reveals an important aspect of being an individual: solving problems in a space different from that occupied by its parts. While individual cells cannot ascertain the right number, size or position of eyes or fingers, tissues do so routinely, that is, the tissue as a collective executes morphogenesis through differential cell reproduction and differentiation, stopping when the correct structure is complete. While cells navigate transcriptional and metabolic spaces, cellular collectives can navigate anatomical morphospaces and the conventional behavioural space.


Altered states: Basal cognition and manipulated target morphology. This framework makes a strong prediction: if intercellular signalling (not genes) is the cognitive medium of a morphogenetic individual, it should be possible to exploit the tools of behavioural and neuro-science and learn to read, interpret and re-write its information content in a way that allows predictive control over its behaviour (in this case, growth and form) without genetic changes. This prediction has been validated in several species. The bioelectric signatures that drive accurate regenerative reproduction/development in planaria have been identified (‘reading and interpreting’ anatomical target information). Planaria normally have one head, but this is not genetically determined, merely a default: transient bio-electrical modulation of the body-wide pattern memory circuits can shift them to a persistent two-headed state, causing subsequent pieces of that planarian to regenerate into two-headed worms (‘re-writing’). This induced phenotype then persists through future rounds of amputation until set back to normal with a different bioelectrical manipulation; it even exhibits features of advanced individual cognition such as bi-stability. These target morphology shifts occur despite the fact that all of the individual cells have unaltered normal genomes, showing that competent subunits can be pushed to implement diverse organism-scale goals by physiological signals (experiences) without modification of their essential hardware. In addition, this can happen rapidly – not requiring evolutionary timeframes. Other examples of reading, interpreting and re-writing the bioelectric information dictating morphogenesis have been described in a range of model systems. Consistent with the idea that cellular swarms can act as a consolidated cognitive agent, morphogenesis is known to be altered by prior experiences (e.g. amphibian limbs ceasing to regenerate after repeated amputation) and confused by exposure to classic cognitive modifier drugs.

Bioelectricity: A ‘cognitive glue’ common to collective and individual intelligence. The many parallels between behavioural control by nervous systems, and the ancestral capacity of morphogenetic control by all cell networks, are reviewed elsewhere. But it's crucial to note that the very same cognitive glue – bioelectrical networks implemented by ion channels and electrical synapses – operates to bind neurons into competent individuals in the 3D world of behaviour and to bind other cell types into competent individuals in the morphogenetic space of anatomical control. These insights are now driving computational models used to understand the tissue-level decision making that results in birth defects and their repair, giving rise to promising therapeutics.

These capacities of morphogenetic cellular collectives are basally cognitive insomuch as they involve information integration and coordinated action, characteristic of a self. More radically, perhaps this kind of cognition is actually what constitutes organismal individuality – that is, the processes of basal cognition essential for achieving specific system-level goals in anatomical morphospace are exactly what make the whole different from a collection of parts.

Collective intelligence as a product of evolutionary selection, or evolutionary selection as a product of collective intelligence?

Biological individuality has traditionally been associated with the scope of an evolutionary unit - the unit that is subject to differential survival and reproduction. Within this orthodox view, whilst the processes of developmental basal cognition are certainly complicated and might have the appearance of collective behaviour, they are merely complex parts of a single individual. However, this view turns out to be wholly inadequate to understand and manipulate the multi-scale nature of life.

Genetic identity and biological individuality. The idea that biological individuality can be defined by genetic identity is clearly insufficient: the structural and functional demarcations of coherent individuals often diverge from their genetic information. Note that a colony of bacteria may be genetically homogeneous but not an individual, while planaria are biological individuals by any reasonable sense of the word but not genetically homogeneous. Even though genetically identical, the tissues and cells within a classical organism (body) often compete with each other; conversely, cells from distant species cooperate well within chimeric organisms. In addition, genetic information does not always predict the structure and function of bioelectrically modified organisms or of self-organising synthetic living machines. Likewise, often it is the degree of bioelectrical coupling, not genetic differences, that determines whether cellular optimisation occurs at the single-cell level (cancer) vs. at the organ-level (normal morphogenesis).

Evolutionary units and biological individuality. Can a notion of evolutionary units beyond genetic relatedness rescue a meaningful concept of biological individuality? That is, the ability to exhibit heritable variation in reproductive success might obtain for a complex or composite whose components are not genetically related. For example, despite being of separate ancestral origins, the nuclear and mitochondrial DNA of eukaryotes can be considered a single evolutionary unit (under most conditions) by the virtue of their common vertical transmission. However, identifying what exactly constitutes an evolutionary unit in general is also non-trivial especially because they change over evolutionary time and new units arise at new levels of organisation.

To be a bona fide evolutionary unit, a collective must exhibit heritable variation in reproductive success that belongs properly to the collective level – over and above the sum of that exhibited by its component parts. This requires organised functional relationships that cause short-sighted self-interested entities to behave in a manner that serves the long-term collective interest of the whole. In this light, the complex nature of functional relationships between component parts begins to look less like the product of selection at the system level, and more like the source of evolutionary individuality.

Practical implications: Beyond philosophy. Such considerations matter fundamentally to our understanding of the organismic, evolutionary and developmental biology (i.e., emergent functionality) and thus to our ability to predict, control, manage and manipulate multi-scale biological systems. Understanding what kind of relationships instantiate biological individuality is thus of great importance to synthetic bioengineering, regenerative medicine, exobiology, robotics and artificial intelligence.


For example, to intervene in the processes that coordinate component parts to create or regenerate an organ or a limb or produce an entirely novel construct such as a self-assembling biobot – we must be able to manipulate the very relationships that define individuality. Such bioengineering goals therefore depend intimately on our knowledge of collective intelligence at multiple levels of biological organisation. Recent work has begun to apply the tools of collective intelligence and cognitive neuroscience to morphogenesis and its disorders, including cancer, a disease of dysregulated morphogenesis. Disconnection from the bioelectric network of tissues often gives rise to fragmenting of coherent anatomical individuals into invasive single cells and tumors; their release from higher level collective goals is readily apparent because they pursue anatomical, histological and physiological states quite different from those that the organism tries to maintain. This fragmentation can be reversed: despite strong oncogenic mutations, cancer phenotypes can be suppressed by forcing bioelectrical connections among cells, thus overriding single-cell level goals with large-scale morphogenetic ones.


Cognition, learning and problem-solving in biological networks: Generalised principles of connectionism

The link between evolution and simple types of learning has often been noted but sometimes interpreted in an uninteresting way: learning is simply a form of random variation and selection. However, the formal equivalence between evolution and learning also has a much more interesting implication, namely: Evolution is more intelligent than we realised. Connectionist models of conventional learning, familiar in artificial neural networks, greatly expand this perspective. Connectionist models inherently implement the fact that intelligence resides not in the parts but in the organisation of the relationships between them. Such models demonstrate how networks of organised functional relationships between simple reactive (stateless) components are sufficient to exhibit information integration and coordinated responses. Moreover, these relationships can be organised by simple distributed, incremental processes, that is, learning.

Hebbian learning in networks. A simple example of such a neural model, demonstrating distributed computation and learning, is the Hopfield network. Given that the Hopfield network is inspired by neural dynamics and learning in cognitive systems, its learning and problem-solving abilities are perhaps not so surprising, despite their decentralised operation. However, the underlying principles are extremely simple and general: the same computational algorithms also apply in systems that we don’t normally expect to be capable of cognition or learning; gene-regulation networks, protein interaction networks and ecological community networks can all implement the same kinds of functions as neural networks if organised appropriately. However, cognition in different substrates may have very different spatio-temporal scales from the cellular, to the familiar organismic scale, and perhaps to the ecological scale. Can these kinds of networks also learn as neural networks do?

The answer is yes. Hebbian learning in a self-modelling dynamical system effects a positive feedback on correlations; the more things co-occur, the more the connection between them changes to make them more likely to co-occur in future. This positive feedback on correlations is quite natural. In some conditions, it does not require an active learning mechanism that strengthens connections, instead it is sufficient to differentially relax or weaken connections according to the frustration or stress experienced in that connection. Thus, connectionist modes of cognitive learning can be instantiated in various kinds of non-neural networks.

Importantly, the application of connectionist models also extends into the domain of evolutionary systems, where the connections of a network are changed by variation and selection, as seen in the evolution of interaction networks in development and ecology. In these ‘evolutionary connectionism’ models, ordinary processes of random variation and selection act on the functional interactions between components, altering their organisation in a way that positively reinforces correlations functionally equivalent to connectionist learning models. The algorithmic principles well-understood in neural networks, are equally demonstrable in gene-regulation networks, and ecological community networks and social networks. This algorithmic unification between connectionist learning and evolution opens up the transfer of an extensive, well-developed toolset from machine learning into evolutionary theory to naturalistically explain evolutionary ‘intelligence’.

In particular, it is important to recognise that connectionist models can exhibit learning bottom-up, without centralised control or an external teacher, and without any performance feedback applied at the system level, via fully distributed and unsupervised learning principles. This means that the same learning behaviours can be exhibited by an ecological community without selection at the community level. This is potentially important to understanding the evolution of intelligent collectives (and evolutionary transitions in individuality (ETIs)) because it identifies conditions where relationships between evolving entities can be organised via natural selection acting at the lower level before selection at the higher level takes effect.


So, what kind of cognition can such networks exhibit?. We find it useful to operationalise cognition in an algorithmic sense, namely: what kind of problem-solving can it do? Organisms solve problems in many different spaces including morphological, metabolic, transcriptional or behavioural. Limited forms of problem-solving can be demonstrated with simple networks like the Hopfield model. The problem-solving behaviour of such a system without learning can be taken as a base line, or null model, as it merely describes a local energy descent process with fixed points corresponding to locally optimal solutions (of the energy-minimisation problem implicit in the constraints between its components). To do better than that – to avoid being trapped in local minima – requires a system to learn an internal organisation that knows something about the solution space from past experience, either on agent timescales (the familiar scale of cognition) or on evolutionary timescales.

The ability of distributed learning to improve problem-solving ability in this way is now well-developed. In some conditions, a learning neural network can enable a sort of ‘chunking’, rescaling the search process to a higher level of organisation. Elsewhere, we hypothesise that this rescaling of the problem-solving search process is intrinsic to transitions in individuality, suggesting that ETIs constitute a form of deep model induction.

Credit assignment in individuals and collectives

Conventional accounts of intelligence and behavioural protocols assume a singular subject of intelligence and of the goals that it can pursue. However, this is a significant over-simplification that obscures important questions about how centralised intelligences arise out of cellular components. For example, one trains a rat to press a lever and receive a delicious reward, in instrumental or associative learning paradigms. The rat is understood to be an intelligent agent solving an instrumental learning problem; but it is also a collection of cells. Indeed, the cells that perform the action (muscle and skin cells that interact with the lever) and the ones involved in sensing the environment (seeing the lever, feeling the lever and tasting the reward) are not the cells that immediately receive the nutritional benefit of the reward (intestinal lining). No individual cell has the entire experience of performing an action and reaping its benefits – that relationship only exists in the ‘group mind’ of the collective agent. How do the parts discern which of their actions should be reinforced? Problems of distributed credit assignment are a key aspect of intelligence, even in conventional organisms.


It is imperative to understand the developmental algorithms and signals by which tissue-level agents incentivise lower-level subunits (e.g. cells and molecular pathways), distorting their option space so that simple, local descent down free-energy paths (short-sighted self-interest) result in higher order adaptive activity (long-term collective interest). The key to being an individual is to have a functional structure in which diverse experiences across its components are bound together in a way that generates causal relationships and composite memories that belong to the higher space of the individual and not its components.


How does scaling of reward dynamics bind subunits into intelligent collectives that better navigate novel problem spaces? Lessons from machine learning. It is no accident that the issue of credit assignment, and the application of credit to parts or wholes, is a central one in evolutionary selection, developmental and organismic biology and cognitive science. It is a feature of many difficult learning tasks that they require sequences of actions that are many steps away from ultimate goals – making it intrinsically difficult to incentivise the component parts involved. This is what makes difficult tasks difficult; conversely, having feedbacks that are additive and individual, is what makes easy tasks easy. It is no coincidence then, that these issues of credit assignment have well-developed formalisms in the domain of machine learning. In particular, one of the touchstones of machine learning – the ability to represent non-linearly separable functions (such as XOR – Exclusive OR logical operator) – is distinguished from linearly separable functions exactly because improvements in the output cannot be ascribed to the independent contribution of individual inputs. Nonetheless, simple connectionist models can learn such functions if they have a suitable architecture.

Connectionist models thus identify some basic criteria about the kind of relationships that turn a collection of unintelligent components into a non-decomposable intelligence with cognitive and learning abilities that belong properly to the whole and not the parts. Moreover, the ability of unsupervised learning processes to exhibit collective problem-solving capabilities suggests conditions where this can arise bottom-up, using only distributed learning mechanisms without pre-supposing collective-level feedback. These principles do not require that the collective is already an evolutionary unit, nor do they require that the members of the collective are neurons.


Together, these observations show that the apparent distinction between individual intelligence and collective intelligence is not substantial: at a minimum, they exist on a continuum. Further, the connectionist models of cognition and learning developed for individual intelligence are not simply relevant to understanding what is required for a collective to be intelligent, it may be that it is precisely these cognitive capacities that are the fundamental difference-maker with respect to individuality itself; i.e. between ‘many individuals’ and ‘one individual’.

What kinds of interaction structures are necessary for what kind of (collective) intelligence and how can these structures emerge?

Some of the different cognitive behaviours we might be interested in for collective intelligence include information integration, holding state over time, storing and recalling multiple memories and recognising past states, generalising, problem-solving and multi-scale autonomy. Moreover, we are interested in how any of these behaviours can be understood to belong to the whole – or indeed, to multiple organisational scales – rather than the parts. Whilst some of these behaviours might not be very well defined in the context of collective behaviour, our approach is to describe how they relate to the different types of connectionist architectures, familiar in artificial neural networks, where these behaviours are better understood. This approach offers a speculative synthesis of machine learning concepts with basal cognition and evolutionary theory – and a roadmap of gaps and opportunities for future research in collective intelligence. We first discuss what interaction structures are needed and then how such structures can emerge ‘bottom-up’ through distributed learning mechanisms.

The structure of interactions

Naturally, the ability to represent relationships (e.g. correlations or associations) among variables, rather than a system of independent variables, is essential for any connectionist model of cognition, and requires components to have connections of one kind or another. For example, in development, gap-junctions between non-neural cells are physiologically tunable ‘synapses’ that communicate cellular behaviours and indeed can drive genetically wild-type cells to build body organs belonging to diverse species. There are many other levels of biological organisation with different ‘signals and responses’ between components, or sensitivity to one another’s behaviours. Being connected is necessary but not sufficient for cognitive functions, however. Connectionist principles enable us to be more specific about what kinds of connection structure are important.


Instructive neural architectures from machine learning. This is by no means a survey of machine learning techniques or a comprehensive description of neural architectures; our aim is simply to highlight some of the key architectural issues and their significance with respect to different cognitive abilities. Three particular architectural issues have special significance:


1. *Feed-forward mappings and recurrent dynamics:* Artificial neural networks are often used to represent (and learn) a mapping between inputs and outputs (e.g. for classification or regression tasks). One of the simplest ‘feed-forward’ networks is the single-layer Perceptron where an output node fires if the sum of its weighted inputs exceeds a threshold (more generally the output is some non-linear monotonic function, e.g. a sigmoidal function, of the weighted sum of inputs). This is capable of representing simple input-output relationships and learning to classify inputs according to such relationships. In other cases, connections can be recurrent, that is, connections can form loops and thus states can be influenced by inputs from previous time steps and the system can continue to hold internal state after the input is removed. They can also, thereby, exhibit temporally extended dynamical behaviours. Accordingly, in recurrent networks we are often interested in the dynamical attractors of the system (which are a function of the system’s own internal history not just current inputs) rather than instantaneous values of designated outputs or the input-output relationship. The Hopfield network is a simple example. Because connections are symmetric (with no self-connections) in the Hopfield network, its dynamics have only fixed point attractors (‘memories’), but more general recurrent architectures may have periodic or chaotic dynamical behaviours.

2. *Deep representations and non-linearly separable functions:* The single-layer Perceptron has important limitations. Specifically, although it can represent ‘linearly separable functions’ where the response to a change in one input changes magnitude depending on the value of another input (i.e. the responses are not independent), it cannot represent non-linearly separable functions where the response to a change in one input changes direction depending on the value of another input. This type of interdependence is important because in the linearly separable case, if an input contributes positively to an output in one context, it never contributes negatively in another. This means the single-layer Perceptron can represent cases where ‘working together’ changes the benefit an individual input can receive (from doing what they were doing anyway), but it cannot represent cases in which working together requires an individual to do the opposite behaviour, move in the other direction or do something opposed to what they were doing when they worked alone or in some other context. Representing non-linearly separable functions requires a network with multiple layers – a multi-layer Perceptron (MLP). In principle, an MLP can represent any function of the inputs given sufficient ‘hidden’ variables (units that are neither inputs nor outputs but constitute an intermediate layer of representation). In practice, it is frequently useful to employ more layers (with fewer nodes each) because this affords a different inductive bias and generalisation. These are known as deep networks.


3. *Deep and recurrent networks:* Whilst there are many other architectures used in artificial neural networks, two others are worth mentioning. A deep auto-encoder is a network that compresses a high-dimensional input space into a low-dimensional representation. A decoder decompresses the low-dimensional representation back into the original high-dimensional space. The compressed encoding can be interpreted as a low-dimensional model of the samples observed on the input space. Changes to the variables of the compressed representation produce large, coordinated changes to the variables in the input space. Lastly, the deep belief network (DBN) is quite a special type of network, and its architecture has particularly relevant properties. The DBN has a layered architecture that can be used to learn compressed representations like the auto-encoder, and within each layer the nodes have recurrent connections. This gives the DBN both the potential to represent low-dimensional recodings of the original input space and to have dynamical attractors that stably retain their state at that higher level of representation.


Implications for evolutionary intelligence and basal cognition

Naturally, for a collection of individuals to exhibit any kind of collective intelligence, it is, at the very least, necessary that the behaviour of one individual has some sensitivity to the behaviour of another. Such interactions can coordinate behaviours to take advantage of scenarios where the benefit/reward or fitness that one individual receives is sensitive to the behaviour of another. However, if this credit-assignment interaction (or fitness epistasis) constitutes a linearly separable function this is not really a difficult problem; although the benefit they receive will vary in different contexts, the behaviour that maximises their benefit is always the same. In contrast, when the credit that one individual receives has an interaction with the credit that another individual receives which constitutes a non-linearly separable function (or reciprocal sign epistasis), this requires that one individual can change its behaviour (or ‘do the opposite’) depending on the context of what other individuals are doing. For a collective to coordinate behaviours to take advantage of such interactions, it must be able to represent non-linearly separable functions, which requires the interaction structure between individuals to have some depth.

These are just the kind of relationships that make the credit assignment or fitness of the whole not only different from the sum of the rewards/fitnesses of the parts but also a non-decomposable function. Intuitively, this changes our relationship from ‘how good this is for me depends on what you are doing’ to ‘what is best for me to do depends on what you are doing’. This is important because, when it is reciprocal, the fitness-affecting characteristics of one component only have meaning in the context of the other. In other words, it creates a ‘we’; what we are doing, for example, whether our behaviours are coordinated or not, becomes a relevant variable.

Deep representations also have a special significance in recurrent networks. In non-hierarchical networks, the many connections between components can cause the system to hold state over time (i.e. internal states can be maintained as dynamical attractors even when the inputs to the network are removed or have changed). This enables the network to exhibit temporally extended behaviours, but it also has the effect that it becomes difficult to change the system state and, therefore, to be sensitive to system inputs. Getting out of one dynamical basin of attraction and into another can require large and/or specific state perturbations. The system acts as a whole but cannot ‘change its mind’ easily. This