[PAGE 1] Machine learning for hypothesis generation in biology and medicine: exploring the latent space of neuroscience and developmental bioelectricity

[PAGE 2] Introduction

The scientific enterprise depends critically not only on the skills
needed to definitively test crisp hypotheses,1-7 but also on the
much less well-understood step of acquiring insights and
fruitful research directions.⁸⁻⁹ Many recent discussions¹⁰,¹¹ have
focused on the fact that while modern "big data" methods are
generating a deluge of facts and measurements, it is increas-
ingly more important to be “building the edifice of science, in
addition to throwing bricks into the yard".¹² In other words, it is
essential that we develop strategies for deriving novel insights
and deep hypotheses that cross traditional (in many cases,
artificial) boundaries between disciplines. We must improve, at
a pace that keeps up with technological and data science
advances, our ability to identify symmetries (invariances)
between sets of observations and approaches to unify and
simplify where possible by identifying large-scale patterns in
research literature and thus motivate and enhance new research
programs (Fig. 1).

One set of tools that is being rapidly developed and ubiqui-
tously deployed originates in the advances of the field of arti-
ficial intelligence.¹³⁻¹⁵ Machine learning is clearly poised to help
science.¹⁴,¹⁶⁻¹⁹ It is becoming widely recognized that “robot
scientist" platforms can not only provide number crunching,
automation, and high throughput, but could potentially also
guide research by identifying what experiments to do next.²⁰⁻²²
Machine learning tools have been suggested to be essential for
progress in the bioinformatics of shape²³⁻²⁶ (moving beyond
molecular information to understand organ- and organism-
level form and function), and developmental biology.²⁷,²⁸ Not
surprisingly, much emphasis is currently placed on improving
the factuality of the output of AI tools; this parallels the well-
developed notions of strong inference and hypothesis-testing
in science: the well-established algorithm of falsifying and
removing incorrect ideas. What is much less well-understood,
but ultimately as crucial, is the process that provides a pool of
interesting hypotheses from which to winnow until provisional
truths are found. Our contribution attempts to bolster this
second component of the scientific process - ideation - with
a new AI-based tool for human scientists that provides input
into the canonical scientific method.

Recent work in this field includes the AI-based discovery of
testable models of regenerative anatomical regulation,²⁹ which
were subsequently empirically validated,³⁰ and similar efforts in
genomics,²² chemistry³¹–³² and biomaterials.³³ One of the most
potentially important current gaps is the paucity of tools for
assisting with the most creative aspect of the work: identifying
deep commonalities between disparate functional datasets, to
enable generalized insight from the ever-growing literature.
Tools are needed that would take meta-hypotheses of human
scientists and mine the published studies for information that
can be used to turn those conceptual hunches into actionable
research programs.

One interdisciplinary area in which computer-assisted
discovery would be most welcome is real-time physiology that
controls form and function in vivo. How large-scale anatomy and
behavior arises from the operation of molecular processes is
a canonical systems biology problem.³⁴ It is currently handled by
two distinct fields, with their own educational tracks, confer-
ences, journals, funding bodies, and paradigms: neuroscience
and developmental biology. Interestingly however, recent work
has suggested that these may share an important underlying set
of dynamics.³⁵⁻³⁷ Neuroscience has long understood that
behavior and cognition are driven by the physiological informa-
tion processing by neural networks, which signal via electrical
events at their membranes.³⁸⁻⁴¹ Likewise, a long history of clas-
sical work has suggested that bioelectric signaling of all kinds of
cells is required as an instructive set of influences that help direct
complex developmental and regenerative morphogenesis.⁴²⁻⁴⁴
Interestingly, recent advances in the molecular understanding of
developmental bioelectricity⁴⁵⁻⁴⁷ has begun to blur the bound-
aries between those disciplines⁴⁸,⁴⁹ (Fig. 2).

[PAGE 3] Specifically, it has been conjectured that the immense
functional capabilities of brains have their origin in the more
ancient, and slower, bioelectric networks that began operation
at the emergence of bacterial biofilms⁵⁰⁻⁵⁴ and were heavily
exploited by evolution to orchestrate metazoan morphogen-
esis.⁵⁵,⁵⁶ The idea that the same algorithms for scaling cellular
activity into larger competencies (such as regulative morpho-
genesis and intelligent behavior) are used in the brain and in
the body (Fig. 3) has many deep implications, for example with
respect to porting methods from neuroscience and behavioral
science into biomedicine,³⁵,⁵⁷,⁵⁸ to take advantage of neurosci-
ence's successful paradigms for managing multi-scale causality
and inferring effective interventions.

The proposed symmetry between cellular swarms using
collective dynamics to solve problems in anatomical morpho-
space and in 3D classical behavioral space has been empirically
tested in specific contexts,³⁴,⁴⁷ and has significant implications
for biomedicine and evolutionary biology.⁵⁹,⁶⁰ However, there
has been no way to derive these hypotheses at scale from the
plethora of functional literature of neuroscience and develop-
mental biophysics. Specifically, it has been claimed that the
deep similarity between the role of bioelectric networks in
control of body shape (cellular collectives' behavior) and
cognition (organism-level behavior) enables one to readily read
neuroscience papers as if they were developmental biology
papers, by only pivoting problem spaces (from 3D space to
anatomical morphospace) and time scales (from milliseconds
to minutes).⁴⁹,⁵⁶ However, there has never been an efficient way
to implement this conjecture and actually explore the latent
space of hypothetical papers that could provide candidate
hypotheses and potentially fruitful research directions.

Here, we provide a first-generation tool, FieldSHIFT, that
helps human scientists explore the mapping between develop-
mental bioelectricity and neuroscience and begins the journey
towards exploring the space of scientific studies far wider than
what has already been written. FieldSHIFT is an in-context
learning framework which uses a large language model to
convert existing paper abstracts in neuroscience to the field of
developmental biology, by appropriately replacing specific
words and concepts. We show that this process generates
useful, readable, insightful results that can be used to expand
scientific intuition and identify testable hypotheses for novel
work at the intersection of two fields. Furthermore, we test some
of the resulting predictions using a bioinformatics approach,
revealing a remarkable quantitative conservation of genes
between developmental morphogenesis and cognitive behavior.

The described system is a first step on the road to using AI tools
as an imagination enhancing tool for research, deriving novel
insights from expensive published experiments and letting
scientists explore life-as-it-could-be.⁶¹ We tested one of the
predictions of its output, finding a quantitatively significant
enrichment in overlap between specific genes implicated in
both cognitive processes and morphogenesis.

There have been a handful of related research efforts using
generative AI for hypothesis generation and cross-domain
knowledge discovery. One such approach is MechGPT, a large
language model for identifying and probing analogous concepts

[PAGE 4] Methods

We propose FieldSHIFT: a framework for domain translation
with modular components in the form of training data and an
AI language model for mapping text from one domain to
another. We constructed a dataset of neuroscience and devel-
opmental biology sentences and associated concepts to test
FieldSHIFT with two AI language models. We used trained
biologists to both build the dataset and evaluate the model
translations. While we focused on mapping neuroscience to
developmental biology text, we believe a similar approach could
be taken to apply FieldSHIFT to other domains.

[PAGE 5] Data

As an exercise with students and other researchers, the Levin
Lab has been translating neuroscience to development biology,
by hand, for several decades. They'd do this by changing
concepts like "brain" to "body", "millisecond" to "minute", and
"neuron" to "cell". We collected 70 such translation pairs. Using
these concept pairs, we constructed translations varying from
one sentence to abstract-length paragraphs by matching
neuroscience passages with corresponding developmental
biology passages. These passages include a variety of text from
facts about these scientific domains to recently published

[PAGE 6] abstracts from neuroscience and developmental biology arti-
cles. We collected 1437 translation samples in total. The average
length of a sample input or output passage is 209 characters,
and the standard deviation is 375. Below is an example pair
pertaining to "brain” as the neuroscience concept and "body" as
the developmental biology concept:

Neuroscience: “The brain is a complex system of neurons that
are interconnected by synapses."
Developmental Biology: “The body is a complex system of cells
that are interconnected by gap junctions."

In addition to translations, in some cases we added the same
developmental biology abstract as both input and output
examples. The goal was to teach a model trained on these
examples not to change anything in the case that development
biology text is provided as input. The six abstracts (corre-
sponding to papers⁶⁵⁻⁷⁰) we used in this way were selected by
choosing developmental biology papers produced by the Levin
Lab. We published the full dataset on Hugging Face for re-use
by the community: https://huggingface.co/datasets/levinlab/
neuroscience-to-dev-bio/tree/main.

To train and test models for domain translation, we
randomly split the dataset according to the neuroscience
concepts associated with each sample. An effective domain
translator should be able to generalize beyond the concepts it
sees during training, demonstrating general knowledge of both
domains and an ability to both identify new concepts within the
input domain and an ability to map those concepts to corre-
sponding concepts in the output domain. As such, we split the
concepts into 43 training, 6 validation, and 21 test concepts
without overlap via random sampling. After splitting concepts,
we split the passages associated with these concepts into 503
train, 50 validation, and 57 test passages by searching for each
concept name within the passage (after normalizing the text by
stripping punctuation, lowercasing, and ignoring extra white-
space characters). Because some concepts mapped to more
passages, we repeated the process until we achieved close to this
desired ratio of train, validation, and test samples (roughly 10×
the number of train samples as validation and test) without
looking at the resulting data until settling on a desirable ratio.

[PAGE 6] Domain translation with machine learning

We implemented and tested two domain translation
approaches for research paper abstracts using pretrained
language models to identify a suitable backend model for
FieldSHIFT. The first is inspired by neural machine translation
(NMT) and abstractive summarization and uses the open-source
BART⁷¹ pretrained Transformer language model (LM).⁷² The
pretrained BART model is designed for summarizing text.
Rather than have the model generate a summary of an input
sample, we fine-tuned it to map neuroscience text to develop-
mental biology text using the domain translation dataset. The
second model we implemented uses in-context learning⁷³ to
prompt the GPT-4 (ref. 74) large language model (LLM) to
complete the task of translating neuroscience text into devel-
opmental biology text. We used human evaluation from trained
biologists to test the effectiveness of these approaches by having
each model generate translations and counting successful ones
according to expert judgement. For more details on the testing
procedure, see the model validation section.


Transformer LMs, and recently, LLMs, which demonstrate
emergent capabilities when scaled to billions of parameters,⁷⁵
are highly expressive deep neural networks used to represent
sequences, especially text data, and have achieved state-of-the-
art performance on a variety of natural language tasks.⁷⁶⁻⁷⁸
LMs are typically pretrained to learn general representations of
text from large, unannotated corpora, then fine-tuned for
specific, downstream natural language tasks. Both NMT and
summarization involve the task of text generation, conditioning
on an input text sequence to generate an output text sequence.
We exploit this symmetry in our first domain translation
approach using BART by continuing to fine-tune an encoder-
decoder LM⁷² already trained for summarization. This neural
architecture embeds discrete textual characters from an input
sequence in a vector space. It then generates an encoded

[PAGE 7] representation of the text in a hidden, latent space in a manner
that captures word order (encoder layer). Next, it decodes the
latent space, conditioning on previously generated words and
the encoder hidden state (decoder layer). Finally, it predicts the
next word in the output sequence using the decoder output.
Greedily predicting the most likely word at each step is unlikely
to generate the best overall output sentence, while selecting the
most likely output sentence in its entirety is computationally
infeasible. As such, we used Beam Search⁷⁹ to select the top-k
most likely output words given an input sentence and
encoder-decoder model parameters.

We continued fine-tuning the pretrained BART LM⁷¹ first
fine-tuned as an abstractive summarizer (and available via
Hugging Face transformers) for domain translation by feeding
the summarizer text pairs specific to our translation task. We
selected the BART LM for its pretraining procedure designed for
text generation, its performance on summarization bench-
marks, and its public availability. A key advantage of the BART
architecture is the way it combines ideas from other popular
and effective Transformer neural networks, specifically bidi-
rectional encoding via corruption of input text as in ⁷⁰ and
autoregressive decoding as in the GPT family of models.⁸¹

Recent decoder-only GPT models such as GPT-3,⁸¹
InstructGPT,⁸² and GPT-4 have proven even more powerful than
encoder-decoder models when scaled to billions of parameters
and trained on sufficiently large corpora.⁸³ Furthermore,
Instruction Fine-Tuning and Reinforcement Learning with
Human Feedback⁸² have led to human-like, and in some cases,
beyond human-level performance on text generation tasks with
decoder-only LLMs. The key idea of these models is to frame all
downstream tasks as text generation with no intermediate
encoding step and align the outputs from the model to human
expectations using Reinforcement Learning to reward the
model for generating desirable text. Once such a model has
been pretrained and instruction fine-tuned, given some starting
input, such as a request or a series of patterns, the LLM can
generate text which fulfills the request or completes the pattern

[PAGE 8] in a stunningly human-like fashion. We selected and used the
GPT-4 LLM based on its superior performance to other LLMS.⁷⁴

[PAGE 8] Model training

Here we describe the core ideas and training procedures for the
two domain translation models we used within FieldSHIFT:
fine-tuned BART and GPT-4.

The core idea of the BART-based domain translator is to learn
a mapping from one text domain to another. This learning process
is illustrated in the top section of Fig. 4. The process for generating
new developmental biology text using the trained model is illus-
trated in the bottom section. During continued fine-tuning of the
BART model, we fed two types of text pairs which we call positive
and negative samples. Positive samples are neuroscience abstracts/
sentences we want to translate into developmental biology
abstracts/sentences, and negative samples are developmental
biology abstracts/sentences which should remain untouched. This
teaches the model to leave existing developmental biology texts as

[PAGE 9] they are. An additional benefit of this strategy is that the model
sees more examples of developmental biology text during
continued fine-tuning, which comes "for free” as no human-time
is required to generate these negative pairs. We sourced both
from the domain translation dataset described above.

We used Beam Search with k = 5 beams to generate the next
output token from the predicted probabilities of each token
given by the decoder at each decoding step. We used the final
predicted text sequence and the encoded ground truth text
consisting of either the same developmental biology abstract as
was provided as input text (for negative samples) or the corre-
sponding output developmental biology text from a human-
generated pair (for positive samples) to compute cross-entropy
loss, then updated the weights of the BART encoder-decoder
over many epochs of training using the AdamW optimizer⁸⁴ with
a learning rate of 0.00005, weight decay of 0.01, batch size per
device of 1, and 128 gradient accumulation steps. We selected
the final model according to cross-entropy loss on the validation

[PAGE 10] set after 8 epochs of no improvement. The 503 training, 50
validation, and 57 test examples generated via our neuroscience
concept split were used to train, validate, and test the model.

The core idea of the GPT-4-based domain translator is also to
learn mappings from neuroscience to developmental biology
text. It does this via text generation and in-context learning as
shown in Fig. 5. When prompting the model, we provided
translation example concept mappings such as those listed
below. The full set of concepts was sourced from our domain
translation dataset.

• Neuron > Cell
• Neural > Cellular
• Behavior > Morphogenesis

To use the GPT-4 LLM as a domain-translator, we provided
in-context examples and asked the LLM to complete the pattern.
We did not update the weights of GPT-4, rather we simply ran
inference using training examples within the prompt. We
sampled these in-context examples from the train concepts of
our domain translation dataset and validated the pattern
completions on abstracts corresponding to test concepts. In this
way, we measured whether GPT-4 can generalize and translate
new concepts not seen among the in-context examples. We
hypothesized that the very large pretraining set (much of the
text on the internet) used to build GPT-4 contains many

[PAGE 11] neuroscience and developmental biology concepts, and thus,
the model is able to use information stored within its layers
pertaining to these concepts in order to both identify new
concepts from the same domain, i.e., a neuroscience concept in
the test set but not in the train set, and map these concepts to
developmental biology concepts not provided as sample
outputs in the in-context examples.

The following illustrates how we tested GPT-4. It includes
a very simple way to prompt GPT-4 to translate from neurosci-
ence to developmental biology. It consists of our prompts and
GPT responses.

[PAGE 13] Results

[PAGE 13] Comparing domain translators

A quantitative evaluation of domain translation methods via
human annotation suggests the effectiveness of ML-based
domain translation. According to both annotators (annotator
1 and 2), the GPT-4-based domain translator with self-critique
generated good translations according to the annotation
criteria for over half of the neuroscience abstracts provided. The

[PAGE 14] GPT-4 approach performed significantly better than the BART
approach (P = 0.017) according to annotator 1 who compared
ML methods. Both annotators graded more real abstracts as
good than ML-generated abstracts, however, this difference was
significant only for annotator 1 (Tables 1 and 2).

While there were more false positives when generating
abstracts with ML, the approach is far more scalable than
humans writing abstracts. The GPT-4-based domain translator

[PAGE 16] Discussion

[PAGE 16] Machine learning for domain translation

We proposed FieldSHIFT, a framework for domain translation. To
implement FieldSHIFT, we built a domain translation dataset and
compared two ML approaches for domain translation using this
data and expert evaluation of the translations. Expert evaluation
identified that the GPT-4-based approach produced good trans-
lations, leading to a useful hypothesis or insight about develop-
mental biology, in about 20 out of every 33 tries. This suggests that
new hypotheses in developmental biology can be produced at

[PAGE 16] Bioelectricity: conserved mechanisms and algorithms
between control of body and behavior

It has been previously hypothesized that the algorithms of
behavior (active inference, perceptual control, collective decision-
making, memory and learning, navigation of problem spaces,
preferences, pursuit of goal states with degrees of flexible
response, etc.) are used to direct morphogenesis and may even
derive from it evolutionarily.⁵⁵,⁵⁶,⁹⁹ Here, we produce a tool that
can be used to explore the symmetries and commonalities
between these two fields, and in fact any other two fields. By
translating abstracts of papers from one set of vocabulary into
another, we generate new ways to think about data and potential

[PAGE 16] Latent space of scientific papers

We believe that this work is just the beginning of the AI-guided
exploration of the latent space around scientific papers, in the
sense of the "adjacent possible”.¹⁰⁰,¹⁰¹ Each real scientific paper in
the literature provides access to an associated set of possible

[PAGE 13] Conclusion

The increased overlap we observed between genes implicated in
morphogenesis and behavior has a number of implications for