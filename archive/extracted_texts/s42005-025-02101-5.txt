Neuroevolution of decentralized decision-making in N-bead swimmers leads to scalable and robust collective locomotion

Many microorganisms swim by performing larger non-reciprocal shape deformations that are initiated locally by molecular motors. However, it remains unclear how decentralized shape control determines the movement of the entire organism. Here, we investigate how efficient locomotion emerges from coordinated yet simple and decentralized decision-making of the body parts using neuroevolution techniques. Our approach allows us to investigate optimal locomotion policies for increasingly large microswimmer bodies, with emerging long-wavelength body shape deformations corresponding to surprisingly efficient swimming gaits. The obtained decentralized policies are robust and tolerant concerning morphological changes or defects and can be applied to artificial microswimmers for cargo transport or drug delivery applications without further optimization "out of the box". Our work is of relevance to understanding and developing robust navigation strategies of biological and artificial microswimmers and, in a broader context, for understanding emergent levels of individuality and the role of collective intelligence in Artificial Life.

Microorganisms are ubiquitous in nature and play an essential role in many biological phenomena, ranging from pathogenic bacteria affecting our health to phytoplankton as a key player in the marine ecosystem on a global scale. A large variety of microorganisms live in viscous environments, and their motion is governed by the physics of low Reynolds number hydrodynamics, where viscous forces dominate over inertia. As a consequence, a common strategy is to periodically deform their body shape in a non-reciprocal fashion to swim. To thrive in the environment, they have developed different tailored strategies to exploit their swimming capabilities, such as actively navigating toward a nutrient-rich source, hunting down prey, escaping predators, or reproducing. Besides being of direct biological relevance, understanding the corresponding navigation strategies of microorganisms bears potential for biomedical or technical applications, potentially utilized by synthetic microswimmers deployed as targeted drug delivery systems.

Nature has evolved many different strategies and control mechanisms for microswimmers to swim fast, efficiently, and adaptive to environmental conditions: For example, swimming algae cells or sperm cells move with the help of waving cilia or flagella, respectively, or amoebae such as Dictyostelium and unicellular protists such as Euglenia by deforming their entire cell body. The associated deformation amplitudes and wavelengths can be on the order of the entire size of the organism.

In the last years, Reinforcement Learning (RL) has been applied to understand navigation strategies of microswimmers, for example under external fluid flow or external fields, or to perform chemotaxis in the presence of chemical gradients. So far, most of these studies treat microswimmers as rigid agents, i.e., explicitly omitting body deformations or other internal degrees of freedom, and simply manipulate their ad hoc swimming speed and rotation rates for control purposes to perform well in a particular environment. Only very recent contributions consider the constraints of physically force-free shape-deforming locomotion of plastic model microswimmers in an effort to identify swimming gaits that explicitly utilize the hydrodynamic interactions between different body parts in a viscous environment. Modeling such a body-brain-environment offers explicit and more realistic behavior of the response of an organism to environmental conditions.

The locomotion of microswimmers and microrobots moving in viscous fluids at low Reynolds numbers can be modeled with various numerical methods of different accuracy. Examples for actively deforming slender filaments as they occur in biological systems or in soft robotics are slender body theory, or Cosserat rod models. Yet the simplest models, which usually outperform the aforementioned methods in terms of computation time, discretize a filament or a microswimmer by interconnected beads where hydrodynamic interactions are captured in the far-field limit, such as in the Oseen or Faxén approximation. These models are particularly useful for Evolutionary Algorithms (EAs) in RL, which rely on the efficient simultaneous simulation of a whole population of microswimmers.

A prominent and very simple and efficient model that has frequently been investigated with RL techniques is the (generalized) Najafi-Golestanian (NG) microswimmer, typically consisting of N = 3 (or more) concentrically aligned beads immersed into a viscous environment. Such a composite N-bead NG microswimmer can self-propel via non-reciprocal periodic shape deformations that are induced by coordinated time-dependent periodic forces applied to every bead, which sum up to zero for force-free microswimmers. Conventional strategies to describe the autonomous locomotion of a microswimmer consisting of hydrodynamically interacting beads utilize a centralized controller that integrates all the information about the current state of the microswimmer in its environment (comprising internal degrees of freedom and potential environmental cues such as chemical field concentrations). As such, it proposes control instructions for every actuator in the system, thereby inducing dynamics, i.e., body deformations, that are most optimal for a specific situation given a particular task. To substitute and mimic the complex and adaptable decision-making machinery of biological microswimmers, such controllers are often realized by trainable Artificial Neural Networks (ANNs).

Centralized decision-making relies on the (sensory) input of all individual body parts of a composite microswimmer, i.e., quantities such as the relative positions, velocities, or other degrees of freedom for all N beads, and the corresponding control actions target all system actuators, i.e., what forces to apply to every one of the N beads. While the number of trainable parameters of a controller ANN scales at least quadratically with the number of beads N, the number of possible perceivable states and controlling actions scales in a combinatorial way with the number of degrees of freedom of the sensory input and the action output. This not only immensely complicates deep-learning procedures but essentially renders exhaustive approaches infeasible given the vast combinatorial space of possible input-output mappings for large N. Thus, while generalized NG swimmers with  have been successfully trained to perform locomotion or chemotaxis tasks, they have been limited to a relatively small number of body parts, i.e., a small number of degrees of freedom, , so far.

However, even unicellular organisms are fundamentally made of (many) different parts, which (co-)operate in a seamlessly coordinated way: in biological microswimmers, for example, collective large body deformations are typically achieved through orchestrated and cooperative action of molecular motors and other involved proteins, inducing, e.g., the local deformation of the cilia-forming axoneme via localized contractions and extensions. Consequently, such organisms—without an apparent centralized controller-cooperatively utilize their body components in a fully self-orchestrated way in order to swim by collectively deforming and reconfiguring their body shape. For example, the periodically deforming shapes of eukaryotic flagella are not designed or pre-defined by cellular signals, but are an emerging property of the specific local forces applied by the molecular motors on the filament. Moreover, such decentralized navigation policies tend to be robust and failure-tolerant with respect to changing morphological or environmental conditions, e.g., if parts of the locomotive components are disabled or missing, or unforeseeable situations are encountered. Strong signs of such generalizing problem-solving skills are observed, for example, in cells, slime molds, and swarms, and, as recently suggested, this fundamental ability of biological systems to self-organize via collective decision-making might be the unifying organizational principle for integrating biology across scales and substrates. Thus, the plastic and functional robustness and the innate drive for adaptability found in biological systems might not only further robotics but facilitate unconventional forms of computation based on collective intelligence.

So far, it remains unclear how decentralized decision-making in a deformable microswimmer can lead to efficient collective locomotion of its body parts. We thus investigate biologically motivated decentralized yet collective decision-making strategies of the swimming behavior of a generalized NG swimmer, serving as a simple model system for, e.g., a unicellular organism, or a controllable swimming microrobot. Optimizing collective tasks in systems of artificial agents, such as collectively moving composite (micro)-robots, can be addressed with Multi-Agent Reinforcement Learning (MARL). Typically employed concepts such as Centralized Training with Decentralized Execution (CTDE) often rely on the usage of overparameterized deep neural networks and complex information sharing across agents during training. In contrast to conventional MARL we employ here a recently developed method which utilizes EAs to optimize lean decentralized control policies based on collective performance quantified by a global fitness signal (i.e., without the need for local credit assignment). Such collective agents have a topology reminiscent of Neural Cellular Automata (NCAs), where all distributed agents share the same ANN architecture while exchanging low-bandwidth information between neighbors on the grid of a cellular automaton to update their states and hence the collective behavior in the problem domain; here, the beads of a generalized NG swimmer will be treated as the cells of an NCA which will learn to coordinate locally to exert non-reciprocal bead-specific forces to propagate the collective microswimmer body. Furthermore, in our approach, we are able to overcome earlier limitations by extending our swimmers to much larger  than previously feasible, allowing us to identify locomotion strategies in the limit . To this end, we interpret each bead of the microswimmer's body as an agent that can only perceive information about its adjacent beads and whose actions induce contractions or extensions of its adjacent muscles. We substitute the internal decision-making machinery of such single-bead agents with ANNs and employ genetic algorithms and neuroevolution to machine learn optimal policies for such single-bead decision-making centers, such that the entire N-bead swimmer can efficiently self-propel collectively, i.e., in a decentralized way. We show that the evolved policies are robust and failure-tolerant concerning morphological changes of the collective microswimmer and that such decentralized control—trained for microswimmers with a specific number of beads-generalizes well to vastly different morphologies.


Figure 1: Neuroevolution of decentralized decision-making in N-bead swimmers. (a) Schematics of an N-bead microswimmer environment, with (b) functionally identical yet operationally independent Artificial Neural Networks (ANNs) acting as decentralized decision-making centers (or controllers) to update the respective internal states of the beads,  (red arrows), and to apply bead-specific forces, (green arrows; ensuring ), such that the entire microswimmer self-propels purely based on local perception-action cycles of the constituting bead controllers. (c) The training progress of optimizing various N-bead microswimmer locomotion policies of type A (see the "Modeling system-level decision-making with decentralized controllers" subsection in the "Results and Discussion"), respectively identifying for predefined values of  the parameters of the morphology-specific ANN controllers via evolutionary algorithms (EAs). The fitness score for different N, quantifying a specific N-bead center of mass velocity  (see the "Modeling system-level decision-making with decentralized controllers" subsection in the "Results and Discussion"), is presented over 200 subsequent generations. Opaque-colored areas below the fitness trajectories indicate the corresponding STD of 10 independent EA searches per morphology and serve as a measure for convergence for the optimization process.



Figure 2: Schematics of mapping the bead-specific proposed actions  to the proposed active forces  to ensure the global force-free condition . (a) Schematics by interpreting the actions as force-pairs between neighboring beads (type A microswimmers). (b) Schematics by subtracting the global average from every proposed, bead-specific action  (type B microswimmers).

Note 2), the internal states sᵢ assist the decision-making of the localized agents in the collective microswimmer via non-trivial exchange of information between neighboring beads (e.g., as self-orchestrated positional markers of the beads within the body, or as intrinsic pace-makers stabilizing dynamics, etc.). We find that at least a single hidden state dim(s) ≥ 1 significantly improves the training efficiency on locomotion tasks, and while this might be the case for more complex environments, no further gains in swimming speed are expected in our system for dim(s)>2.

Third, we here utilize a fixed ANN architecture and deploy it to every single-bead agent, as illustrated in Fig. 8 (see ref. 58): we partition a bead's ANN into a sensory module, f⁽ˢ⁾(·), and a policy module f⁽ᵖ⁾(·). The sensory module maps each neighbor-specific input separately into a respective sensor embedding, εᵢⱼ (tₖ) = f⁽ˢ⁾(pᵢⱼ (tₖ)) ∈ Rᵉᵐᵇᵈ, which are merged into a bead-specific context matrix Cᵢ(tₖ) = (εᵢ₋₁(tₖ), εᵢ₀(tₖ), εᵢ₊₁(tₖ)). The subsequent policy module or controller ANN eventually outputs the action of the beads, aᵢ(tₖ) = f⁽ᵖ⁾(Cᵢ(tₖ)) = (Φᵢ, Δsᵢ), proposing a bead-specific force Φᵢ ∈ [-F₀, F₀] (to-be regularized, Φᵢ→Fᵢ, such that ∑ᵢFᵢ = 0, see the “The N-bead swimmer model" and "Modeling system-level decision-making with decentralized controllers" subsections in the "Results and Discussion") and an internal state update Δsᵢ ∈ Rⁿᶜᵃ.

Fourth, we specifically utilize a single-layer FF sensory module, f⁽ˢ⁾(·), with (N⁽ˢ⁾ = 2 + nᶜᵃ) input and N⁽ˢ⁾ₒ = nᵉᵐᵇᵈ output neurons with a tanh(·) filter (the same network for all 3 neighbors). The (3 × nᵉᵐᵇᵈ) context matrix, Cᵢ, is then flattened into a (3 nᵉᵐᵇᵈ)-dimensional vector, which is processed by the policy module, f⁽ᵖ⁾(·): again, a single FF layer with N⁽ᵖ⁾ = 3 nᵉᵐᵇᵈ and (N⁽ᵖ⁾ₒ = 1 + nᶜᵃ), followed by a clamping filter (·) = max(min(·, -1), 1).

Fifth, we use nᶜᵃ = 2 and nᵉᵐᵇᵈ = 4 in our simulations, resulting in N⁽ˢ⁾ × (N⁽ˢ⁾ + 1) = 20 sensory module parameters, and N⁽ˢ⁾ₒ × (N⁽ᵖ⁾ + 1) = 39 policy module parameters (accounting for the bias vectors), and thus in Nₑ = 59 ANN parameters in total. These parameters were chosen to balance training performance and expected (near-)optimality of the results; any combination of nᶜᵃ, nᵉᵐᵇᵈ≥1 is suitable for the presented system, but small values are not always sufficient to guarantee successful training behavior, and large values increase the number of ANN parameters.

Genetic algorithm and neuroevolution of single-agent policies with collective goals

Genetic Algorithms (GAs) are heuristic optimization techniques inspired by the process of natural selection. In GAs, a set (or a population) of size Nₚ, X = {θ₁, ..., θₙₚ}, of sets of parameters (or individuals), θᵢ ∈ Rᴺ⁰, is maintained and modified over successive iterations (or generations) to optimize an arbitrary objective function (or a fitness score), r(θᵢ) : Rᴺ⁰ → R. Many Genetic- or EA implementations have been proposed, which essentially follow the same biologically-inspired principles: Starting from an initial, often random population, high-quality individuals are selected (i) from the most recent generation for reproduction, depending on their associated fitness scores. Based on these selected high-fitness "parent" individuals, new "offspring" individuals are sampled, e.g., by genetic recombination (ii) of two mating parents, i, j, by randomly shuffling the elements (or genes) of their associated parameters, schematically expressed as θ = θᵢ⊗θⱼ. Such an offspring's genome can be subjected to random mutations (iii), typically implemented by adding zero-centered Gaussian noise with a particular STD, ξ₀, to the corresponding parameters, θ→θ + ξ. The offspring then either replace (iv) existing individuals in the population or are discarded depending on their corresponding fitness score, r(θ). In that way, the population is successively updated and is thus guided towards high-fitness regions in the parameter space, Rᴺ⁰, over many generations of successive reproduction cycles.

Here, we utilize D. Ha's "SimpleGA" implementation (following steps (i-iv) above) to optimize the ANN parameters, θ, of the single-bead agents of the here investigated N-bead microswimmers, see "The N-bead swimmer model” and “Modeling system-level decision-making with decentralized controllers" subsections of the "Results and Discussion,” and Figs. 1 and 8: After initializing the ANN parameters of a population of size Nₚ = 128 by sampling from a zero-centered Gaussian of STD σ₀ = 0.1, we successively (i) select at each generation the best 10% of individuals for the reproduction cycle (ii, iii)-according to the fitness score r = (vτ) that quantifies a swimmers mean center-of-mass velocity as detailed in the "Modeling system-level decision-making with decentralized controllers" subsection in the "Results and Discussion"-and (iv) replace the remaining 90% of the population with sampled offsprings; we fix the mutation rate in step (iii) to ξ = 0.1 and typically perform multiple independent GA runs for 200–300 generations (see Fig. 1) each to ensure convergence of the evolved policies. For every parameter set θ (per run, and per generation), we evaluate the fitness score as the average fitness of 10 independent episodes, each lasting for T = (400-800) environmental time-steps. For every episode, we randomize the respective N-bead swimmer's initial bead positions as xᵢ(0) ~ N(μ = iL₀, σ = R) drawn from a standard normal distribution centered around μ = i L₀ with a STD of r = R, and evaluate the episode fitness as mean center of mass velocity vτ (see the "Modeling system-level decision-making with decentralized controllers" subsection in the "Results and Discussion").

Swimming-gait analysis

In the “Transferable evolved policies: decentralized decision-making generalizes to arbitrary morphologies" subsection of the "Results and Discussion,” we define a 2π-period governing equation lᵢ(t) = f ((t − iτ) ω + φ) for the actual arm lengths lᵢ(tₖ) for both type A and B N-bead microswimmers as a function of the mean angular velocity ω = <ω(N)> and the mean neighbor arm cross-correlation time τ = τ(N). For all evolved type A and B microswimmer policies utilized in Fig. 4a and b, we thus evaluate the corresponding mean angular velocity as ω̄ = ∑ᵢⁿ⁻¹ ωᵢ by averaging the most dominant angular velocities ωᵢ extracted for every arm length lᵢ(t) of a particular swimmer realization via Fourier transformation. We further define τ̄ = ∑ᵢ τᵢ, with τᵢ being the optimal time delay between neighboring arm lengths lᵢ(t) and lᵢ₊₁(t+τᵢ) maximizing the overlap |∫₀¹ lᵢ(t)lᵢ₊₁(t + τᵢ) dt|τᵢ = 0.

Data availability

The data that support the plots within this paper and other findings of this study are available from the corresponding author upon request.

Code availability

The simulation code and output data are available upon reasonable request to the corresponding author.


References

(References 1-94)


The Author(s) 2025